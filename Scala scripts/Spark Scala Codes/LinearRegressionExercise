import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.regression.LinearRegression
//import org.apache.spark.sql.functions._
import org.apache.log4j._
//import org.apache.spark.SparkContext
//error message on the screens
Logger.getLogger("org").setLevel(Level.ERROR)

val spark = SparkSession.builder().getOrCreate()

val data = spark.read.format("csv").option("header" , "true").option("InferSchema" , "true").csv("Clean_Ecommerce.csv")
//val data = spark.read.format("csv").option("header" , "true").option("InferSchema" , "true").load("Clean_USA_Housing.csv")

data.printSchema()
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.linalg.Vectors

val colnames = data.columns
val firstrow = data.head(1)(0)

println("\n")
println("example data row")

for(ind <- Range(1,colnames.length)){
println(colnames(ind))
println(firstrow(ind))
println("\n")}

val df = data.select(data("Yearly Amount Spent").as("label") , $"Avg Session Length" , $"Time on App" , $"Time on Website" , $"Length of Membership")
df.printSchema()
df.show(3)

val assembler = new VectorAssembler().setInputCols(Array("Avg Session Length" , "Time on App" , "Time on Website" , "Length of Membership")).setOutputCol("features")

val output = assembler.transform(df).select($"label" , $"features")
output.show(3)

val lr = new LinearRegression()
val lrmodel = lr.fit(output)
val trainingSummary = lrmodel.summary
trainingSummary.residuals.show(3)

println(s"numIterations: ${trainingSummary.totalIterations}")
println(s"objectiveHistory: ${trainingSummary.objectiveHistory.toList}")


println(s"RMSE: ${trainingSummary.rootMeanSquaredError}")
println(s"MSE: ${trainingSummary.meanSquaredError}")
println(s"r2: ${trainingSummary.r2}")