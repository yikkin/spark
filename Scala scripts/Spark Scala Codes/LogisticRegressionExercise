import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.log4j._

Logger.getLogger("org").setLevel(Level.ERROR)

val spark = SparkSession.builder().getOrCreate()

val data = spark.read.format("csv").option("header" , "true").option("InferSchema" , "true").csv("advertising.csv")
data.printSchema

//data.show(3)

// val colnames = data.columns 
// val firstrow = data.head(1)(0)

// for(ind <- Range(1,colnames.length)){
// println(colnames(ind))
// println(firstrow(ind))
// println("\n")}

val timedata = data.withColumn("Hour" , hour(data("Timestamp")))

val logregdata = timedata.select(data("Clicked on Ad").as("label"), $"Daily Time Spent on Site", $"Age", $"Area Income", $"Daily Internet Usage", $"Hour" , $"Male")
//val logregdata = logregdataall.na.drop()

import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer , VectorAssembler , VectorIndexer}
import org.apache.spark.ml.linalg.Vectors

val assembler = new VectorAssembler().setInputCols(Array("Daily Time Spent on Site", "Age", "Area Income", "Daily Internet Usage","Hour")).setOutputCol("features")
 
val Array(training , test) = logregdata.randomSplit(Array(0.7 , 0.3) , seed = 12345)
import org.apache.spark.ml.Pipeline

val lr = new LogisticRegression()
val pipeline = new Pipeline().setStages(Array(assembler , lr))

val model = pipeline.fit(training)
val results = model.transform(test)

// For Metrics and Evaluation
import org.apache.spark.mllib.evaluation.MulticlassMetrics

// Need to convert to RDD to use this
val predictionAndLabels = results.select($"prediction",$"label").as[(Double, Double)].rdd

// Instantiate metrics object
val metrics = new MulticlassMetrics(predictionAndLabels)

// Confusion matrix
println("Confusion matrix:")
println(metrics.confusionMatrix)