import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.log4j._

Logger.getLogger("org").setLevel(Level.ERROR)

val spark = SparkSession.builder().getOrCreate()

val data = spark.read.format("csv").option("header" , "true").option("InferSchema" , "true").csv("titanic.csv")
//data.printSchema

//data.show(3)

// val colnames = data.columns
// val firstrow = data.head(1)(0)

// for(ind <- Range(1,colnames.length)){
// println(colnames(ind))
// println(firstrow(ind))
// println("\n")}

// val logregdataall = data.select(data("Survived").as("label"),$"Pclass",$"Sex",$"Age",$"SibSp",$"Parch",$"Ticket",$"Fare",$"Cabin",$"Embarked")
// val logregdata = logregdataall.na.drop()

// Grab only the columns we want
val logregdataall = data.select(data("Survived").as("label"), $"Pclass", $"Sex", $"Age", $"SibSp", $"Parch", $"Fare", $"Embarked")
val logregdata = logregdataall.na.drop()

import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer , VectorAssembler , VectorIndexer}
import org.apache.spark.ml.linalg.Vectors

//converting string into numerical values
val genderIndexer = new StringIndexer().setInputCol("Sex").setOutputCol("SexIndex")
val embarkIndexer = new StringIndexer().setInputCol("Embarked").setOutputCol("EmbarkIndex")

//converting numerical values into one hot encoding 0 or 1
val genderEncoder = new OneHotEncoder().setInputCol("SexIndex").setOutputCol("SexVec")
val embarkEncoder = new OneHotEncoder().setInputCol("EmbarkIndex").setOutputCol("EmbarkVec")

val assembler = new VectorAssembler().setInputCols(Array("Pclass" , "SexVec" , "Age" , "SibSp" , "Parch" , "Fare" , "EmbarkVec")).setOutputCol("features")

val Array(training , test) = logregdata.randomSplit(Array(0.7 , 0.3) , seed = 12345)
//val df = assembler.transform(logregdataall)
import org.apache.spark.ml.Pipeline

val lr = new LogisticRegression()
val pipeline = new Pipeline().setStages(Array(genderIndexer, embarkIndexer , genderEncoder , embarkEncoder , assembler , lr))

val model = pipeline.fit(training)
val results = model.transform(test)

// For Metrics and Evaluation
import org.apache.spark.mllib.evaluation.MulticlassMetrics

// Need to convert to RDD to use this
val predictionAndLabels = results.select($"prediction",$"label").as[(Double, Double)].rdd

// Instantiate metrics object
val metrics = new MulticlassMetrics(predictionAndLabels)

// Confusion matrix
println("Confusion matrix:")
println(metrics.confusionMatrix)
