import spark.implicits._
import org.apache.spark.sql.{DataFrame , Row}
import org.apache.spark.sql.types.{StructType , StructField , StringType , IntegerType}
import org.apache.spark.sql.SparkSession
import org.apache.log4j._

val spark = SparkSession.builder().getOrCreate()

// val rdd = sc.parallelize(List(25,18,25,70,65,15))
// val rdd2  = rdd.map(x=>(x,1))
// val rdd3 = rdd2.reduce((x,y) => (x._1 + y._1 , x._2+ y._2))
// val avg_age = rdd3._1/rdd3._2


//creation dataframe avec manipulation sql
//val macollection = List((1,"Junon" , 30),(64,"Deborah" , 46) ,(24,"Isa" , 24),(37,"Jacques" , 28))
//val  madf = macollection.toDF("id","prenom","age")

val rowrdd = sc.parallelize(Seq(Row("john", 27),Row("eric",25),Row("joel" , 20)))

val schema = new StructType().add(StructField("name",StringType, true)).add(StructField("age", IntegerType,true))
val df = spark.createDataFrame(rowrdd , schema)

df.createOrReplaceGlobalTempView("equipe")
val dfsql = spark.sql("select * from global_temp.equipe where age > 20")
//val df_age_under20 = df.select($"age <20").show()
df.registerTempTable("equipes")
val dfsql2 = spark.sql("select name , age from equipes where age > 20")





